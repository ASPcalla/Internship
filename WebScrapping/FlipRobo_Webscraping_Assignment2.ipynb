{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "229411ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\nitu calla\\appdata\\roaming\\python\\python310\\site-packages (4.11.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\nitu calla\\appdata\\roaming\\python\\python310\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\nitu calla\\appdata\\roaming\\python\\python310\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\nitu calla\\appdata\\roaming\\python\\python310\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\nitu calla\\appdata\\roaming\\python\\python310\\site-packages (from trio~=0.17->selenium) (1.1.3)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\nitu calla\\appdata\\roaming\\python\\python310\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\nitu calla\\appdata\\roaming\\python\\python310\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67c60014",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import selenium\n",
    "from selenium import webdriver  # this webdriver module to open automated chrome window\n",
    "import pandas as pd  # to create dataframe\n",
    "from selenium.webdriver.common.by import By  # importing inbuild class by\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01193c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19c2d3bf",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "552976a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "dedbcd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.shine.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "b30c1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation = driver.find_element(By.ID,\"id_q\")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "768fe390",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "cbfc821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,\"searchForm_btnWrap_advance__VYBHN\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "c025cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experiance_required =[]\n",
    "url= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "8668283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//h2[@itemprop=\"name\"]') \n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "\n",
    "# Scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "# Scraping company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "\n",
    "# Scraping job experiance from the given page\n",
    "experiance_tags=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in experiance_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experiance_required.append(exp)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "7aca1343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experiance_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "6fc395f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experiance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore\\n+13</td>\n",
       "      <td>rama technical consultants</td>\n",
       "      <td>11 to 21 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>now Data Analyst</td>\n",
       "      <td>Bangalore\\n+8</td>\n",
       "      <td>apidel technologies private limited</td>\n",
       "      <td>4 to 7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring Data Analyst</td>\n",
       "      <td>Bangalore\\n+8</td>\n",
       "      <td>apidel technologies private limited</td>\n",
       "      <td>2 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore\\n+8</td>\n",
       "      <td>apidel technologies private limited</td>\n",
       "      <td>2 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Data Analyst, GlowRoad</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>amazon</td>\n",
       "      <td>1 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst - Java/Python</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring IN - DCS Data Analyst</td>\n",
       "      <td>Bangalore\\n+8</td>\n",
       "      <td>apidel technologies private limited</td>\n",
       "      <td>2 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IN - DCS Data Analyst</td>\n",
       "      <td>Bangalore\\n+8</td>\n",
       "      <td>apidel technologies private limited</td>\n",
       "      <td>3 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Project Coordinator (Data Analyst)</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>futures and careers</td>\n",
       "      <td>2 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring For Data Analyst</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>kavya staffing solutions</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Title        Location  \\\n",
       "0                        Data Analyst  Bangalore\\n+13   \n",
       "1                    now Data Analyst   Bangalore\\n+8   \n",
       "2                 Hiring Data Analyst   Bangalore\\n+8   \n",
       "3                        Data Analyst   Bangalore\\n+8   \n",
       "4     Business Data Analyst, GlowRoad       Bangalore   \n",
       "5          Data Analyst - Java/Python       Bangalore   \n",
       "6        Hiring IN - DCS Data Analyst   Bangalore\\n+8   \n",
       "7               IN - DCS Data Analyst   Bangalore\\n+8   \n",
       "8  Project Coordinator (Data Analyst)       Bangalore   \n",
       "9             Hiring For Data Analyst  Bangalore\\n+14   \n",
       "\n",
       "                             Company Name    Experiance  \n",
       "0              rama technical consultants  11 to 21 Yrs  \n",
       "1     apidel technologies private limited    4 to 7 Yrs  \n",
       "2     apidel technologies private limited    2 to 6 Yrs  \n",
       "3     apidel technologies private limited    2 to 4 Yrs  \n",
       "4                                  amazon    1 to 3 Yrs  \n",
       "5  boyen haddin consulting and technol...    3 to 6 Yrs  \n",
       "6     apidel technologies private limited    2 to 4 Yrs  \n",
       "7     apidel technologies private limited    3 to 5 Yrs  \n",
       "8                     futures and careers    2 to 4 Yrs  \n",
       "9                kavya staffing solutions    0 to 4 Yrs  "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now making DF\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title,'Location':job_location,'Company Name':company_name,'Experiance':experiance_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2371cdc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3002f936",
   "metadata": {},
   "source": [
    "Q2:Write a python program to scrape data for “Data Scientist” Job position in“Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter “Data Scientist” in “Job title, Skills” field and enter “Bangalore” in “enter thelocation” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "2066dae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "91080b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.shine.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "d5e3a150",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation = driver.find_element(By.CLASS_NAME,\"form-control\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "5eafc413",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "473805f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,\"searchForm_btnWrap_advance__VYBHN\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "93045dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experiance_required =[]\n",
    "url= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "57cbcdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//h2[@itemprop=\"name\"]') \n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "\n",
    "# Scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "# Scraping company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "\n",
    "# Scraping job experiance from the given page\n",
    "experiance_tags=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in experiance_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experiance_required.append(exp)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "9b5a87ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experiance_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "200f541f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experiance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist Recruitment</td>\n",
       "      <td>Bangalore\\n+17</td>\n",
       "      <td>kavya staffing solutions</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Bangalore\\n+17</td>\n",
       "      <td>kavya staffing solutions</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Bangalore\\n+17</td>\n",
       "      <td>kavya staffing solutions</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>skyleaf consultants</td>\n",
       "      <td>5 to 10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist Bangalore</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>skyleaf consultants</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist Urgent Recruitment</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>divya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Required for Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>deuglo infosystem private limited</td>\n",
       "      <td>4 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Urgently need Data Scientist</td>\n",
       "      <td>Bangalore\\n+8</td>\n",
       "      <td>deuglo infosystem private limited</td>\n",
       "      <td>4 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data scientist Bangalore</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>seven geomax consulting private lim...</td>\n",
       "      <td>6 to 9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>employberry consultants hiring for ...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Title        Location  \\\n",
       "0         Data Scientist Recruitment  Bangalore\\n+17   \n",
       "1          Hiring For Data Scientist  Bangalore\\n+17   \n",
       "2          Hiring For Data Scientist  Bangalore\\n+17   \n",
       "3                     Data Scientist       Bangalore   \n",
       "4           Data Scientist Bangalore       Bangalore   \n",
       "5  Data Scientist Urgent Recruitment  Bangalore\\n+14   \n",
       "6        Required for Data Scientist       Bangalore   \n",
       "7       Urgently need Data Scientist   Bangalore\\n+8   \n",
       "8           Data scientist Bangalore       Bangalore   \n",
       "9                     Data Scientist       Bangalore   \n",
       "\n",
       "                             Company Name   Experiance  \n",
       "0                kavya staffing solutions   0 to 4 Yrs  \n",
       "1                kavya staffing solutions   0 to 4 Yrs  \n",
       "2                kavya staffing solutions   0 to 4 Yrs  \n",
       "3                     skyleaf consultants  5 to 10 Yrs  \n",
       "4                     skyleaf consultants   3 to 6 Yrs  \n",
       "5                       divya interprises   0 to 4 Yrs  \n",
       "6       deuglo infosystem private limited   4 to 6 Yrs  \n",
       "7       deuglo infosystem private limited   4 to 6 Yrs  \n",
       "8  seven geomax consulting private lim...   6 to 9 Yrs  \n",
       "9  employberry consultants hiring for ...   3 to 6 Yrs  "
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now making DF\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title,'Location':job_location,'Company Name':company_name,'Experiance':experiance_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b446bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d7a978f",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage \n",
    "\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the web page https://www.shine.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scrapeddata.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "9a173542",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "fbb64bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.shine.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "8f3b9b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation = driver.find_element(By.CLASS_NAME,\"form-control\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "66e8b803",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,\"searchForm_btnWrap_advance__VYBHN\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "84dff4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_button = driver.find_element(By.XPATH,'//i[@class=\"iconH-arrow mx-10\"]')\n",
    "location_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "e2e3aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_filter = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[4]/div/div[1]/div/div[2]/div[2]/div/div/div/div[3]/div/div/div/ul/li[8]/span/label\")\n",
    "city_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "bcfa817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_filter = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[4]/div/div[1]/div/div[2]/div[2]/div/div/div/div[3]/div/ul/li[3]\")\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "ff808ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "Salary_button = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[4]/div/div[1]/div/div[2]/div[2]/div/div/div/div[3]/div/div/div/ul/li[3]/span/label')\n",
    "Salary_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "3d640b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Show_Result_button = driver.find_element(By.XPATH,'//button[@class=\"btn btn-secondary\"]')\n",
    "Show_Result_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "f31d0cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experiance_required = []\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,'//h2[@itemprop=\"name\"]') \n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "\n",
    "# Scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "# Scraping company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "\n",
    "# Scraping job experiance from the given page\n",
    "experiance_tags=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in experiance_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experiance_required.append(exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "725e64a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title[0:10]),len(job_location[0:10]),len(company_name[0:10]),len(experiance_required[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "f8b84cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experiance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DATA SCIENTIST DELHI</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>skyleaf consultants</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATA SCIENTIST DELHI</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>skyleaf consultants</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>quiscon biotech</td>\n",
       "      <td>0 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATA SCIENTIST DELHI</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>skyleaf consultants</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>quiscon biotech</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>skyleaf consultants</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>for _GCP Data Engineer/Lead/Architect- Delhi</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>nina s hr consultancy</td>\n",
       "      <td>2 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>for _GCP Data Engineer/Lead/Architect- Delhi</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>nina s hr consultancy</td>\n",
       "      <td>2 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>quess corp (magna infotech)</td>\n",
       "      <td>4 to 7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Req. For Data Scientist -Reputed Data Analytic...</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>seven consultancy</td>\n",
       "      <td>2 to 6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title   Location  \\\n",
       "0                               DATA SCIENTIST DELHI      Delhi   \n",
       "1                               DATA SCIENTIST DELHI      Delhi   \n",
       "2                                     Data Scientist  Delhi\\n+6   \n",
       "3                               DATA SCIENTIST DELHI      Delhi   \n",
       "4                                     Data Scientist  Delhi\\n+6   \n",
       "5                                     Data Scientist      Delhi   \n",
       "6       for _GCP Data Engineer/Lead/Architect- Delhi      Delhi   \n",
       "7       for _GCP Data Engineer/Lead/Architect- Delhi      Delhi   \n",
       "8                                       Data Analyst      Delhi   \n",
       "9  Req. For Data Scientist -Reputed Data Analytic...      Delhi   \n",
       "\n",
       "                  Company Name  Experiance  \n",
       "0          skyleaf consultants  3 to 6 Yrs  \n",
       "1          skyleaf consultants  3 to 6 Yrs  \n",
       "2              quiscon biotech  0 to 3 Yrs  \n",
       "3          skyleaf consultants  3 to 6 Yrs  \n",
       "4              quiscon biotech   0 to 1 Yr  \n",
       "5          skyleaf consultants  3 to 6 Yrs  \n",
       "6        nina s hr consultancy  2 to 3 Yrs  \n",
       "7        nina s hr consultancy  2 to 3 Yrs  \n",
       "8  quess corp (magna infotech)  4 to 7 Yrs  \n",
       "9            seven consultancy  2 to 6 Yrs  "
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now making DF\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title,'Location':job_location,'Company Name':company_name,'Experiance':experiance_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334141f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be37b913",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "6. Brand\n",
    "7. ProductDescription\n",
    "8. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url :https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search fieldwhere “search for products, brands and more” is written and\n",
    "   click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the required data as      usual\n",
    "4. After scraping data from first page go to second page and scrp data\n",
    "5. repeat till u get 100 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "5d026d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "9b91e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the flipkart.com pag Son the automated chome browser\n",
    "driver.get('https://www.flipkart.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "0f627f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = driver.find_element(By.NAME,\"q\")\n",
    "product.send_keys('Sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "76a84bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element(By.CLASS_NAME,'L0Z3Pu')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "1f9ce582",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands=[]\n",
    "product_descriptions=[]\n",
    "prices=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "a0d0e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_to_scrape=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "09e59b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in range(pages_to_scrape):\n",
    "    time.sleep(3)\n",
    "    \n",
    "    brand_tags=driver.find_elements(By.CLASS_NAME,'_2WkVRV')\n",
    "    for tag in brand_tags[0:100]:\n",
    "        brands.append(tag.text)\n",
    "        \n",
    "    product_descriptions_tags=driver.find_elements(By.CLASS_NAME,'IRpwTa')\n",
    "    for tag in product_descriptions_tags[0:100]:\n",
    "        product_descriptions.append(tag.text)\n",
    "    \n",
    "    price_tags=driver.find_elements(By.CLASS_NAME,'_30jeq3')\n",
    "    for tag in price_tags[0:100]:\n",
    "        prices.append(tag.text)\n",
    "        \n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    if next_button:\n",
    "        next_button.click()\n",
    "    else:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "5bf7db20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(brands[0:100])),print(len(product_descriptions[0:100])),print(len(prices[0:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "f8cc7848",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_length = max(len(brands), len(product_descriptions), len(prices))\n",
    "\n",
    "# Pad shorter lists with default values (e.g., None or empty string) to make them the same length\n",
    "brands += [None] * (max_length - len(brands))\n",
    "product_descriptions += [None] * (max_length - len(product_descriptions))\n",
    "prices += [None] * (max_length - len(prices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "1d87558f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brands</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>₹201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Cat-eye, Retro Square, Oval, Rou...</td>\n",
       "      <td>₹177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Clubmaster Sunglasses (54)</td>\n",
       "      <td>₹245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROADWAY</td>\n",
       "      <td>UV Protection Wayfarer, Sports, Spectacle , Re...</td>\n",
       "      <td>₹294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rich Club</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (54)</td>\n",
       "      <td>₹495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>₹699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>₹539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>₹199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>₹197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>₹294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brands                                Product Description Price\n",
       "0         SRPM             UV Protection Wayfarer Sunglasses (50)  ₹201\n",
       "1    Elligator  UV Protection Cat-eye, Retro Square, Oval, Rou...  ₹177\n",
       "2       PIRASO           UV Protection Clubmaster Sunglasses (54)  ₹245\n",
       "3      ROADWAY  UV Protection Wayfarer, Sports, Spectacle , Re...  ₹294\n",
       "4    Rich Club         UV Protection Retro Square Sunglasses (54)  ₹495\n",
       "..         ...                                                ...   ...\n",
       "130       None                                               None  ₹699\n",
       "131       None                                               None  ₹539\n",
       "132       None                                               None  ₹199\n",
       "133       None                                               None  ₹197\n",
       "134       None                                               None  ₹294\n",
       "\n",
       "[135 rows x 3 columns]"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating Dataframe\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Brands':brands,'Product Description':product_descriptions,'Price':prices,})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392cde34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not getting next page after 2nd page . Also doono why I am getting more than 100 elements ... kinldy help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1a03e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c2bf4ea",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. \n",
    "\n",
    "You have to go the link:\n",
    "\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/product\u0002reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market\n",
    "\n",
    "place=FLIPKART\n",
    "\n",
    "\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews.\n",
    "Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "e4a49fe2",
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: unknown error: net::ERR_NAME_NOT_RESOLVED\n  (Session info: chrome=116.0.5845.141)\nStacktrace:\n\tGetHandleVerifier [0x00007FF7D9AD52A2+57122]\n\t(No symbol) [0x00007FF7D9A4EA92]\n\t(No symbol) [0x00007FF7D991E3AB]\n\t(No symbol) [0x00007FF7D991A161]\n\t(No symbol) [0x00007FF7D990CADF]\n\t(No symbol) [0x00007FF7D990DE82]\n\t(No symbol) [0x00007FF7D990CEB8]\n\t(No symbol) [0x00007FF7D990BFBE]\n\t(No symbol) [0x00007FF7D990BF63]\n\t(No symbol) [0x00007FF7D990A9E5]\n\t(No symbol) [0x00007FF7D990B153]\n\t(No symbol) [0x00007FF7D991FF4B]\n\t(No symbol) [0x00007FF7D998EEF7]\n\t(No symbol) [0x00007FF7D9976FDA]\n\t(No symbol) [0x00007FF7D998EB82]\n\t(No symbol) [0x00007FF7D9976DB3]\n\t(No symbol) [0x00007FF7D994D2B1]\n\t(No symbol) [0x00007FF7D994E494]\n\tGetHandleVerifier [0x00007FF7D9D7EF82+2849794]\n\tGetHandleVerifier [0x00007FF7D9DD1D24+3189156]\n\tGetHandleVerifier [0x00007FF7D9DCACAF+3160367]\n\tGetHandleVerifier [0x00007FF7D9B66D06+653702]\n\t(No symbol) [0x00007FF7D9A5A208]\n\t(No symbol) [0x00007FF7D9A562C4]\n\t(No symbol) [0x00007FF7D9A563F6]\n\t(No symbol) [0x00007FF7D9A467A3]\n\tBaseThreadInitThunk [0x00007FFD435726AD+29]\n\tRtlUserThreadStart [0x00007FFD43B6AA68+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[506], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Opening the flipkart.com pag Son the automated chome browser\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://www. https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC TSVZAXUHGREPBFGI&marketplace.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:345\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    343\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 345\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: unknown error: net::ERR_NAME_NOT_RESOLVED\n  (Session info: chrome=116.0.5845.141)\nStacktrace:\n\tGetHandleVerifier [0x00007FF7D9AD52A2+57122]\n\t(No symbol) [0x00007FF7D9A4EA92]\n\t(No symbol) [0x00007FF7D991E3AB]\n\t(No symbol) [0x00007FF7D991A161]\n\t(No symbol) [0x00007FF7D990CADF]\n\t(No symbol) [0x00007FF7D990DE82]\n\t(No symbol) [0x00007FF7D990CEB8]\n\t(No symbol) [0x00007FF7D990BFBE]\n\t(No symbol) [0x00007FF7D990BF63]\n\t(No symbol) [0x00007FF7D990A9E5]\n\t(No symbol) [0x00007FF7D990B153]\n\t(No symbol) [0x00007FF7D991FF4B]\n\t(No symbol) [0x00007FF7D998EEF7]\n\t(No symbol) [0x00007FF7D9976FDA]\n\t(No symbol) [0x00007FF7D998EB82]\n\t(No symbol) [0x00007FF7D9976DB3]\n\t(No symbol) [0x00007FF7D994D2B1]\n\t(No symbol) [0x00007FF7D994E494]\n\tGetHandleVerifier [0x00007FF7D9D7EF82+2849794]\n\tGetHandleVerifier [0x00007FF7D9DD1D24+3189156]\n\tGetHandleVerifier [0x00007FF7D9DCACAF+3160367]\n\tGetHandleVerifier [0x00007FF7D9B66D06+653702]\n\t(No symbol) [0x00007FF7D9A5A208]\n\t(No symbol) [0x00007FF7D9A562C4]\n\t(No symbol) [0x00007FF7D9A563F6]\n\t(No symbol) [0x00007FF7D9A467A3]\n\tBaseThreadInitThunk [0x00007FFD435726AD+29]\n\tRtlUserThreadStart [0x00007FFD43B6AA68+40]\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Opening the flipkart.com pag Son the automated chome browser\n",
    "driver.get('https://www. https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC TSVZAXUHGREPBFGI&marketplace.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5950c46c",
   "metadata": {},
   "source": [
    "Answer : Link Expired"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19afeb7",
   "metadata": {},
   "source": [
    "Q6: Scrape data forfirst 100 sneakers you find whenyou visit flipkart.com and search for “sneakers” inthe\n",
    "search field.\n",
    "\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "\n",
    "As shown in the below image, you have to scrape the above attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "9608de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Opening the flipkart.com page  \n",
    "driver.get('https://www.flipkart.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "c3b04d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys('sneakers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "08e08344",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element(By.CLASS_NAME,'L0Z3Pu')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "6606144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_to_scrape=2\n",
    "\n",
    "for page in range(pages_to_scrape):\n",
    "    time.sleep(3)\n",
    "    \n",
    "    brand_tags=driver.find_elements(By.CLASS_NAME,'_2WkVRV')\n",
    "    for tag in brand_tags[0:100]:\n",
    "        brands.append(tag.text)\n",
    "        \n",
    "    product_descriptions_tags=driver.find_elements(By.CLASS_NAME,'IRpwTa')\n",
    "    for tag in product_descriptions_tags[0:100]:\n",
    "        product_descriptions.append(tag.text)\n",
    "    \n",
    "    price_tags=driver.find_elements(By.CLASS_NAME,'_30jeq3')\n",
    "    for tag in price_tags[0:100]:\n",
    "        prices.append(tag.text)\n",
    "        \n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    if next_button:\n",
    "        next_button.click()\n",
    "    else:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "4c000c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(brands[0:100])),print(len(product_descriptions[0:100])),print(len(prices[0:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "0d300a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max(len(brands), len(product_descriptions), len(prices))\n",
    "\n",
    "# Pad shorter lists with default values (e.g., None or empty string) to make them the same length\n",
    "brands += [None] * (max_length - len(brands))\n",
    "product_descriptions += [None] * (max_length - len(product_descriptions))\n",
    "prices += [None] * (max_length - len(prices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "125ba4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brands</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>₹201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Cat-eye, Retro Square, Oval, Rou...</td>\n",
       "      <td>₹177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Clubmaster Sunglasses (54)</td>\n",
       "      <td>₹245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROADWAY</td>\n",
       "      <td>UV Protection Wayfarer, Sports, Spectacle , Re...</td>\n",
       "      <td>₹294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rich Club</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (54)</td>\n",
       "      <td>₹495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>₹509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>₹368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>₹539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>₹296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>555 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brands                                Product Description Price\n",
       "0         SRPM             UV Protection Wayfarer Sunglasses (50)  ₹201\n",
       "1    Elligator  UV Protection Cat-eye, Retro Square, Oval, Rou...  ₹177\n",
       "2       PIRASO           UV Protection Clubmaster Sunglasses (54)  ₹245\n",
       "3      ROADWAY  UV Protection Wayfarer, Sports, Spectacle , Re...  ₹294\n",
       "4    Rich Club         UV Protection Retro Square Sunglasses (54)  ₹495\n",
       "..         ...                                                ...   ...\n",
       "550       None                                               None  ₹509\n",
       "551       None                                               None  ₹368\n",
       "552       None                                               None  ₹539\n",
       "553       None                                               None  ₹449\n",
       "554       None                                               None  ₹296\n",
       "\n",
       "[555 rows x 3 columns]"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating Dataframe\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Brands':brands,'Product Description':product_descriptions,'Price':prices,})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25269e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please help why I am getting more than 100 items although I had restricted number to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b46375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d451a680",
   "metadata": {},
   "source": [
    "Q7: Go to webpage https://www.amazon.in/ \n",
    "\n",
    "Enter “Laptop” in the search field and then click the search icon. \n",
    "\n",
    "Then  set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "\n",
    "\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0c537bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Opening the flipkart.com pag Son the automated chome browser\n",
    "driver.get('https://www.amazon.in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0be470a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = driver.find_element(By.ID,\"twotabsearchtextbox\")\n",
    "product.send_keys('Laptop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "3d8decb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element(By.ID,'nav-search-submit-button')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6f311881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose to copy path as other method didnt worked somehow.\n",
    "\n",
    "intel_core7 = driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[6]/span[9]/li/span/a/span\")\n",
    "intel_core7.click()\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3088d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping title\n",
    "title_el=driver.find_elements(By.XPATH,\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']\")\n",
    "title=[]\n",
    "for i in title_el[:10]:\n",
    "    title.append(i.text)\n",
    "    \n",
    "#scraping ratings\n",
    "rating_el = driver.find_elements(By.XPATH,\"//span[@class='a-size-base puis-normal-weight-text']\")\n",
    "rating=[]\n",
    "for i in rating_el[:10]:\n",
    "    rating.append(i.text)\n",
    "rating\n",
    "   \n",
    "# scraping prices   \n",
    "price_el=driver.find_elements(By.XPATH,\"//span[@class='a-price-whole']\")\n",
    "price=[]\n",
    "for i in price_el[:10]:\n",
    "    price.append(i.text)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "0803a998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(title[0:10])),print(len(rating[0:10])),print(len(price[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ec65de1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP Omen 12th Gen Intel Core i7-12700H 16.1 inc...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1,59,199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acer Nitro 5 12th Gen Intel Core i7-12650H Gam...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>99,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dell Inspiron 5430 Laptop, Intel Core i7-1360P...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>86,249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS TUF Gaming F15 (2023) 90WHr Battery, Inte...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1,13,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS TUF Gaming F15, 15.6\"(39.62 cms) FHD 144H...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>76,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo [SmartChoice] IdeaPad Slim 3 Intel Core...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>62,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dell Inspiron 5630 13th Gen Laptop, Intel Core...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS Creator Series Vivobook 14X OLED (2023), ...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>85,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Acer Predator Helios Neo 16 Gaming Laptop 13th...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1,24,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Rating     Price\n",
       "0  ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...    4.0    59,990\n",
       "1  HP Omen 12th Gen Intel Core i7-12700H 16.1 inc...    4.0  1,59,199\n",
       "2  Acer Nitro 5 12th Gen Intel Core i7-12650H Gam...    3.3    99,990\n",
       "3  Dell Inspiron 5430 Laptop, Intel Core i7-1360P...    4.5    86,249\n",
       "4  ASUS TUF Gaming F15 (2023) 90WHr Battery, Inte...    3.4  1,13,990\n",
       "5  ASUS TUF Gaming F15, 15.6\"(39.62 cms) FHD 144H...    3.7    76,990\n",
       "6  Lenovo [SmartChoice] IdeaPad Slim 3 Intel Core...    4.2    62,990\n",
       "7  Dell Inspiron 5630 13th Gen Laptop, Intel Core...    4.6    89,990\n",
       "8  ASUS Creator Series Vivobook 14X OLED (2023), ...    3.6    85,990\n",
       "9  Acer Predator Helios Neo 16 Gaming Laptop 13th...    4.3  1,24,990"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating Dataframe\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':title,'Rating':rating,'Price':price,})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8c1e04",
   "metadata": {},
   "source": [
    "Q8: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "\n",
    "The above task will be done in following steps:\n",
    "\n",
    "1. First get the webpagehttps://www.azquotes.com/\n",
    "2. Click on TopQuotes\n",
    "3. Than scrap \n",
    "    a) Quote \n",
    "    b) Author \n",
    "    c) Type Of Quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "6b06f591",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Opening the flipkart.com pag Son the automated chome browser\n",
    "driver.get('https://www.azquotes.com')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "f734cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_quote = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a')\n",
    "top_quote.click()\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "64785c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Next Button found. Now exiting\n"
     ]
    }
   ],
   "source": [
    "# scraping top 1000 quote\n",
    "start=0\n",
    "end = 1000\n",
    "\n",
    "for page in range (start,end+1):\n",
    "    #scraping quote\n",
    "    quote_el=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    quote=[]\n",
    "    for i in quote_el:\n",
    "        quote.append(i.text)\n",
    "    \n",
    "    #scraping Author name\n",
    "    author_el=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    author=[]\n",
    "    for i in author_el:\n",
    "        author.append(i.text)\n",
    "\n",
    "    #scraping type of quote\n",
    "    type_el=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    type_q=[]\n",
    "    for i in type_el:\n",
    "        type_q.append(i.text)\n",
    "\n",
    "    try:\n",
    "        next_button=driver.find_element(By.XPATH,'//li[@class=\"next\"]') # to scrap data from next pages as well\n",
    "        next_button.click()\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        print('No Next Button found. Now exiting')\n",
    "        break\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "e1f03ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(quote[0:1000])),print(len(author[0:1000])),print(len(type_q[0:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "97cea1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "      <th>Type Of Quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Courage is the price that life exacts for gran...</td>\n",
       "      <td>Amelia Earhart</td>\n",
       "      <td>Inspirational, Life, Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The worst evils which mankind has ever had to ...</td>\n",
       "      <td>Ludwig von Mises</td>\n",
       "      <td>Peace, War, Government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The moment we begin to fear the opinions of ot...</td>\n",
       "      <td>Elizabeth Cady Stanton</td>\n",
       "      <td>Life, Strength, Courage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trust yourself, you know more than you think y...</td>\n",
       "      <td>Benjamin Spock</td>\n",
       "      <td>Positive, Family, Trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Some people want it to happen, some wish it wo...</td>\n",
       "      <td>Michael Jordan</td>\n",
       "      <td>Inspirational, Life, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love, Inspirational, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun, Two, Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Greatness, Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual, Truth, Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The mind is not a vessel to be filled but a fi...</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Inspirational, Leadership, Education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Quote                  Author  \\\n",
       "0   Courage is the price that life exacts for gran...          Amelia Earhart   \n",
       "1   The worst evils which mankind has ever had to ...        Ludwig von Mises   \n",
       "2   The moment we begin to fear the opinions of ot...  Elizabeth Cady Stanton   \n",
       "3   Trust yourself, you know more than you think y...          Benjamin Spock   \n",
       "4   Some people want it to happen, some wish it wo...          Michael Jordan   \n",
       "..                                                ...                     ...   \n",
       "95  Regret for the things we did can be tempered b...        Sydney J. Harris   \n",
       "96  America... just a nation of two hundred millio...      Hunter S. Thompson   \n",
       "97  For every disciplined effort there is a multip...                Jim Rohn   \n",
       "98  The spiritual journey is individual, highly pe...                Ram Dass   \n",
       "99  The mind is not a vessel to be filled but a fi...                Plutarch   \n",
       "\n",
       "                            Type Of Quote  \n",
       "0            Inspirational, Life, Success  \n",
       "1                  Peace, War, Government  \n",
       "2                 Life, Strength, Courage  \n",
       "3                 Positive, Family, Trust  \n",
       "4       Inspirational, Life, Motivational  \n",
       "..                                    ...  \n",
       "95      Love, Inspirational, Motivational  \n",
       "96                 Gun, Two, Qualms About  \n",
       "97  Inspirational, Greatness, Best Effort  \n",
       "98                 Spiritual, Truth, Yoga  \n",
       "99   Inspirational, Leadership, Education  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tried with start as and end with 10 and limit each element to 1000 , still got only 100 output\n",
    "# thus increasing itereration rate from 100 to 1000 and removing limit for elements - still getting 100 output only.\n",
    "\n",
    "# creating Dataframe\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Quote':quote,'Author':author,'Type Of Quote':type_q,})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ebe97d",
   "metadata": {},
   "source": [
    "Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead,\n",
    "Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make theDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d73384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open azquote-click to quote -scrape 1000 quotes- quote + Author + type \n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Opening the flipkart.com pag Son the automated chome browser\n",
    "driver.get('https://www.jagranjosh.com')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42844856",
   "metadata": {},
   "outputs": [],
   "source": [
    "gk_sec = driver.find_element(By.XPATH,'/html/body/div[1]/header/nav/div/div/div[3]/ul/li[3]/a')\n",
    "gk_sec.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da91cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_sec = driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a')\n",
    "pm_sec.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579a693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we nevigated to the list of all prime ministers but the data mentioned here in website is not generalized.\n",
    "# some names are in link form or if we take <td> elements with'style' attribute , it has different dimention in every name.\n",
    "# Kindly suugest solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0715a0",
   "metadata": {},
   "source": [
    "Q10: Write a python program to display list of 50 Most expensive cars in the world \n",
    "\n",
    "(i.e.Car name and Price) from https://www.motor1.com/\n",
    "\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.motor1.com/\n",
    "2. Then You have to type in the search bar ’50 most expensive cars’\n",
    "3. Then click on 50 most expensive carsin the world..\n",
    "4. Then scrap the mentioned data and make the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b384de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Opening the flipkart.com pag Son the automated chome browser\n",
    "driver.get('https://www.motor1.com')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c7197a9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".m1-search-form-button-animate icon-search-svg m1-mobile-search\"}\n  (Session info: chrome=116.0.5845.141); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF7D9AD52A2+57122]\n\t(No symbol) [0x00007FF7D9A4EA92]\n\t(No symbol) [0x00007FF7D991E3AB]\n\t(No symbol) [0x00007FF7D9957D3E]\n\t(No symbol) [0x00007FF7D9957E2C]\n\t(No symbol) [0x00007FF7D9990B67]\n\t(No symbol) [0x00007FF7D997701F]\n\t(No symbol) [0x00007FF7D998EB82]\n\t(No symbol) [0x00007FF7D9976DB3]\n\t(No symbol) [0x00007FF7D994D2B1]\n\t(No symbol) [0x00007FF7D994E494]\n\tGetHandleVerifier [0x00007FF7D9D7EF82+2849794]\n\tGetHandleVerifier [0x00007FF7D9DD1D24+3189156]\n\tGetHandleVerifier [0x00007FF7D9DCACAF+3160367]\n\tGetHandleVerifier [0x00007FF7D9B66D06+653702]\n\t(No symbol) [0x00007FF7D9A5A208]\n\t(No symbol) [0x00007FF7D9A562C4]\n\t(No symbol) [0x00007FF7D9A563F6]\n\t(No symbol) [0x00007FF7D9A467A3]\n\tBaseThreadInitThunk [0x00007FFD435726AD+29]\n\tRtlUserThreadStart [0x00007FFD43B6AA68+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[230], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m input_words \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLASS_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mm1-search-form-button-animate icon-search-svg m1-mobile-search\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m input_words\u001b[38;5;241m.\u001b[39msend_keys(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m50 most expensive cars in world\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:739\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    736\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    737\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 739\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:345\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    343\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 345\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".m1-search-form-button-animate icon-search-svg m1-mobile-search\"}\n  (Session info: chrome=116.0.5845.141); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF7D9AD52A2+57122]\n\t(No symbol) [0x00007FF7D9A4EA92]\n\t(No symbol) [0x00007FF7D991E3AB]\n\t(No symbol) [0x00007FF7D9957D3E]\n\t(No symbol) [0x00007FF7D9957E2C]\n\t(No symbol) [0x00007FF7D9990B67]\n\t(No symbol) [0x00007FF7D997701F]\n\t(No symbol) [0x00007FF7D998EB82]\n\t(No symbol) [0x00007FF7D9976DB3]\n\t(No symbol) [0x00007FF7D994D2B1]\n\t(No symbol) [0x00007FF7D994E494]\n\tGetHandleVerifier [0x00007FF7D9D7EF82+2849794]\n\tGetHandleVerifier [0x00007FF7D9DD1D24+3189156]\n\tGetHandleVerifier [0x00007FF7D9DCACAF+3160367]\n\tGetHandleVerifier [0x00007FF7D9B66D06+653702]\n\t(No symbol) [0x00007FF7D9A5A208]\n\t(No symbol) [0x00007FF7D9A562C4]\n\t(No symbol) [0x00007FF7D9A563F6]\n\t(No symbol) [0x00007FF7D9A467A3]\n\tBaseThreadInitThunk [0x00007FFD435726AD+29]\n\tRtlUserThreadStart [0x00007FFD43B6AA68+40]\n"
     ]
    }
   ],
   "source": [
    "input_words = driver.find_element(By.CLASS_NAME,\"m1-search-form-button-animate icon-search-svg m1-mobile-search\")\n",
    "input_words.send_keys('50 most expensive cars in world')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393e68e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting error as the website is showing no such keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224d2b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2f71c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
